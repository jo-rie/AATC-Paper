In this section, we evalute the trending in three different applications.
In the first application in Section~\ref{sec:application-covid}, we consider the nowcasting of the seven-day hospitalization rate for COVID-19 in Germany.
Section~\ref{sec:application-eda} applies the trending assessment to forecast methods for the number of arrivals in a large emergency department.
In the last application in Section~\ref{sec:application_measurement}, we consider the trending assessment of non-invasive blood pressure measurements compared to invasive blood pressure measurements.

\subsection{Covid nowcasting} \label{sec:application-covid}

Amid the COVID-19 pandemic, the importance of accurate and prompt nowcasts of the pandemic's progression has become evident.
Various indicators measured the pandemic's spread and severity. 
In Germany, the seven-day hospitalization rate was established as a central steering measure for COVID-19 measures in November 2021, and the imposition of severe public restrictions was based on it~\citep{RobertKochInstitute2021}. 
The Robert Koch Institute (RKI) provided preliminary daily reports on the seven-day hospitalization rate.
However, these reports were subject to severe delays and revisions in two sources.
The first source is technical delays in the reporting process, for example, due to different authorities passing the data to the RKI~\citep{RobertKochInstitute2024}.
The second, more systematic source is the structure of the seven-day hospitalization rate.
To a given date, all the cases are allocated whose first positive test result was on that date and who were hospitalized in relation to the disease in the following.
The seven-day hospitalization rate is the average number of those cases per $100,000$ inhabitants on the given date and six days before.
Thus, the final seven-day hospitalization rate can only be reported with a significant delay of more than 70 days, as the hospitalization of infected inhabitants can occur much later than the first positive test.
Nevertheless, as the seven-day hospitalization rate was considered a major indicator of the pandemic's development, many organizations and institutions started to issue nowcasts, including research teams and newspapers.
To collect nowcasts of the seven-day hospitalization rate by different nowcast groups, the COVID19-Nowcasting-Hub was established~\citep{ChairOfEconometricsAndStatisticsAtKarlsruheInstituteOfTechnology2024}.
The nowcasts contain the seven-day hospitalization rate's predictive mean, median, and other quantiles.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics{plots/covid_nowcast/00_true_data.pdf}
    \caption{Realisations.}
    \label{fig:app-covid-true}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics{plots/covid_nowcast/00_nowcast_data.pdf}
    \caption{Same-day nowcasts.}
    \label{fig:app-covid-nowcast}
        \end{subfigure}
    \caption{True and nowcast data of the seven-day-hospitalization in Germany from November 22, 2021, to April 29, 2022 \citep{ChairOfEconometricsAndStatisticsAtKarlsruheInstituteOfTechnology2024}.
    The outliers in the RKI model of values above $10^8$ are removed before the following analysis.}
    \label{fig:app-covid-true-nowcast}
\end{figure}

The data contains eight nowcasts from scientific and public institutions, nowcast communities, and a newspaper, using different input variables, calendar data, and length of training data.
The model structures are diverse, including Bayesian models, generalized additive models, and parametric bootstrapping.
Table~\ref{tab:app-covid-models} in the appendix lists the different abbreviations and the respective names in the COVID19-Nowcasting-Hub.
For information on the model design, we refer to~\citet{Wolffram2023}.
Using the nowcasts, two ensemble methods are constructed using the ensembles' mean or median.
We denote them by ENS-MEAN and ENS-MED.
\citet{Wolffram2023} describes the design of the nowcast tasks and the data submission guidelines for the teams stated in a preregistered study. 
In line with the initial study design, we consider the period from November 22, 2021, to April 29, 2022, as the evaluation period.
For the true values, we use the data from February 8, 2024.
The nowcasts are resolved with regard to all inhabitants and specific geographical and age breakdowns.
We do not expand on the models' performance on specific regions or age groups in Germany and the probabilistic nowcast assessment.
Figure~\ref{fig:app-covid-true-nowcast} displays the true and nowcast data for the evaluation period.
The time comprises the fourth wave's end in December 2021 and nearly the entire fifth wave of the pandemic in Germany, lasting until May 28, 2022~\citep{Tolksdorf2022}.

Table~\ref{tab:app-covid-rmse} summarizes the point evaluation measures for the issued mean of the different models.
The models issue same-day nowcasts for nearly all 159 days of the evaluation period~\citep[for explanations of the missing values, see][Tables A2, A3, and A4]{Wolffram2023}.
The best-performing models in terms of RMSE and MAE are the ILM and RKI models.
The ensemble methods perform worse than the best models regarding the mean location.
The performance of the models is diverse, with more than twice as high RMSE values for the worst models compared to the best models.
Note that the high values for the EPI model could be driven by an exceptionally far-off value at the end of the evaluation period.

In addition to close inspection of the point evaluation measures, assessing the trending of the nowcasts is crucial.
To assess the impact of taken measures and the direction of the curve, it is essential to distinguish between rising and falling hospitalization rates.
If hospitalization rates rise, measures should be tightened, while falling rates might allow for loosening measures.
Especially, asymmetries are of interest to assess whether some models are better at recognizing a fall than a rise or vice versa.

\begin{table}[]
    \centering
    \input{plots/covid_nowcast/01_model_scores}
    \caption{Point evaluation measures for the issued mean of the different models. The evaluation period comprises 159 days. }
    \label{tab:app-covid-rmse}
\end{table}

\subsubsection*{Results}

In the following, we apply the trending assessment of Section~\ref{sec:trending} to the nowcasts of the seven-day hospitalization rate.
We report the trending for the horizons 1, 7, and 14 days.
While horizon one assesses the short-term trending, horizons seven and 14 consider the medium-term trending.
The horizons seven and 14 are particularly interesting, reflecting a usual period until new policy changes are taken.

Before stating the results, we provide background information on the marginal distributions of the true values and nowcasts for the different horizons.
Table~\ref{tab:app-covid-marginals} in Appendix~\ref{sec:appendix-application-covid} presents marginal statistics such as standard deviation and quantiles of the nowcasts and true values.
Overall, the variability and general level of differences grow with the horizon.
The standard deviation increases from roughly 300 for horizon one to 1,200 for horizon seven and 2,000 for horizon 14 days.
Similarly, the 10\%-quantile of differences increases.
The 10\%-quantile is used for the exclusion areas in the trending assessment.
The exclusion area is rectangular; a point falls within it if both $\diffy$ and $\diffx$ are below the respective 10\%-quantile of the absolute differences.
Thus, points are still included in the trending assessment if they are large in one dimension but not in the other, thus ensuring that substantial changes in, for example, $\diffy$ are to be recognized by the nowcast and vice versa.

Table~\ref{tab:app-covid-trending-ratios-lag-7} lists the trending ratios for all models with and without exclusion areas for the horizon of seven days.
The trending ratios without exclusion area range from 0.72 to 0.85 for the horizon of seven days.
The negative trending ratios are higher than the positive trending ratios for all models.
The confidence intervals for the positive and negative trending ratios do not overlap for all models, indicating that the trending ratios are indeed different.
The 10\%-quantile exclusion areas have, at most, an influence of 0.03 on the ratios.
The model with the highest trending ratio is the ILM model, and the model with the lowest is the RKI model.
The confidence intervals between all models overlap.
The positive trending ratio implies a similar ranking of the models, while the negative ratio is second best for the RKI model.
For the horizons of one and 14 days, we refer to Table~\ref{tab:app-covid-trending-ratios-lag-1-14} in Appendix~\ref{sec:appendix-application-covid}.

Figure~\ref{fig:app-covid-cond-prob-trending-ratio-7} shows the conditional trending plots and the trending ratio over the exclusion area for the horizon seven days; the respective plots for the horizons one day and 14 days are shown in Figure~\ref{fig:app-covid-cond-prob-trending-ratio-1-14}.
Here, only the best models in point evaluation measures, ILM, RKI, RIVM, and ENS-MED, are shown to keep the plots easily readable.
If RKI or ILM issues a fall in the hospitalization rate, the probability of a fall is higher than if RIVM or ENS-MED issues a fall.
The opposite is the case for a nowcasted hospitalization rate increase, and the difference between the models' performance is higher.
Similar observations can be made for the horizon of 14 days in Figure~\ref{fig:app-covid-cond-prob-14}.
For a horizon of one day, the models' conditional trending ability difference is less pronounced (see Figure~\ref{fig:app-covid-cond-prob-1}).
The RKI model is still less conclusive when issuing an increase in the hospitalization rate, while RIVM is most informative in that case.
The curves cross for an issued fall, with ENS-MED being on top for issued falls above 250.

The trending ratios for various exclusion areas are shown in Figure~\ref{fig:app-covid-trending-ratio-7}.
In general, the trending ratio increases with larger exclusion areas.
While the RIVM and ENS-MED trending ratios evolve similarly, the RKI and ILM trending ratios get closer.
For the horizon of one day, the RKI trending ratio decreases with increasing exclusion area size while the other models rise (see Figure~\ref{fig:app-covid-trending-ratio-1}).
For the horizon of 14 days, all trending ratio curves increase with the exclusion area size (see Figure~\ref{fig:app-covid-trending-ratio-14}).

\begin{table}
    \centering
    \tiny
    \input{plots/covid_nowcast/30_trending_ratios_lag_7.tex}
    \caption{The trending ratio $\accl[7]$, positive trending ratio $\accpl[7]$, and negative trending ratio $\accml[7]$ for the models with and without exclusion areas for the horizon seven days. The exclusion areas are rectangles centered on the zero points with a width and height of twice the 10\%-quantile of the absolute values of nowcast and true values. }
    \label{tab:app-covid-trending-ratios-lag-7}
\end{table}

\begin{figure}
    \centering
%    \includegraphics{}
    \begin{subfigure}[t]{.48\textwidth}
    \includegraphics{plots/covid_nowcast/40_cond_prob_lag_7}
    \caption{Conditional trending plot.}\label{fig:app-covid-cond-prob-7}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{.48\textwidth}
    \includegraphics{plots/covid_nowcast/40_acc_eps_lag_7}
    \caption{Trending ratio over exclusion area size in $\diffx$.}\label{fig:app-covid-trending-ratio-7}
    \end{subfigure}
    \caption{Conditional trending plot and trending ratio over exclusion area for the nowcasts of the seven-day hospitalization rate ILM, RKI, RIVM, and ENS-MED for the horizon seven days.}
    \label{fig:app-covid-cond-prob-trending-ratio-7}
\end{figure}



\subsubsection*{Discussion}

For all horizons, the influence of the exclusion area on the 10\%-quantile level is negligible.
For example, the trending ratio changes at most by 0.03 for the EPI model with $\accml[14]$.
The exclusion areas are thus not crucial for the trending assessment in the case of the nowcasts of the seven-day hospitalization rate.
The lower bound of confidence intervals is at least 0.68 for all models, indicating that they perform better than random guessing the trend.

Trending assessment evaluates the models differently from point evaluation measures.
RKI is among the best in point evaluation measures but performs worse in trending assessment.
The assessment of asymmetry in the conditional trending plots is crucial for interpreting the trending ratios, with the RKI model being the most prominent example.

Figure~\ref{fig:app-covid-trending-ratio-7} shows that the trending ratio increases with larger exclusion areas. 
This indicates that if the model predicts a large change, the direction is indeed better than when a small change is predicted.

A more extensive training size would be beneficial for assessing the models' performance.
For the evaluation period of 159 days, the trending ratio confidence intervals overlap; thus, no conclusions can be drawn from the trending evaluation.

\subsection{Forecasting emergency department arrivals}\label{sec:application-eda}

In a second example, we consider forecasting the hourly number of arrivals in a large emergency department.
Good forecasts are crucial for planning staff and resources.
Several models are used for predicting hourly outcomes in a study by \citet{Rostami-Tabar2023}.
Every 12 hours, the models issue hourly forecasts for the next 48 hours.
Thus, the management can take measures according to the expected number of arrivals, for example, through redeploying staff and reconfiguring units.

\citet{Rostami-Tabar2023} publish means and probabilistic quantile forecasts, which are evaluated through RMSE, pinball loss, pinball skill scores, and PIT-histograms.
The models are trained on data from April 1, 2014, to February 28, 2018, and evaluated on data from March 1, 2018, to February 28, 2019.
For further notes on the models and the evaluation, we refer to \citet{Rostami-Tabar2023}.
From the issued forecasts, we use the mean as a point forecast for the trending assessment and evaluate the probabilistic trending subsequently.
We use the forecasts issued at the first time point for every target time.
Thus, the forecasts are issued 36 to 48 hours ahead of the target time, and the emergency department management has time to adjust the measures according to the expected number of arrivals.
Considering only the forecasts of at least 36 hours ahead, we restrict the evaluation period to March 2, 2018, at noon, to February 28, 2019, at 23:00, comprising 8,724 hours.

In this setup, trending assessment is a simple and intuitive way to assess the models' performance.
The trending perspective is easy for the management to understand and implement, as simple comparisons of the expected workload to a recent shift can be made.
If, for example, the staff was near capacity in the last shift and an increase in the number of arrivals is expected, the management can take measures to adjust the workload.

The number of arrivals has a strong weekly and daily pattern.
Thus, we consider the horizons of 72 hours, the last already observed shift of the same hour of day, and seven days, the previous shift of the same hour and day.
Table~\ref{tab:app-eda-point-evaluation} lists the point evaluation measures and the count of available forecasts.
The best-performing models regarding RMSE and MAE are the NBI-2 and Poisson-2 models.
More than 8,600 forecasts are available for all models, with differences in the number due to missing values on four afternoons in 2018.
Note that the reported values for the RMSE differ from those in \citet{Rostami-Tabar2023}.
In contrast to their work, we use only the forecast data at least 36 hours ahead and not the entire forecast data for evaluation.

\begin{table}
\centering
\input{plots/ed_arrival/00_point_evaluation_measures}
\caption{Point evaluation measures for the models. The smaller count for some models stems from missing forecasts scattered throughout the evaluation period.}\label{tab:app-eda-point-evaluation}
\end{table}


\subsubsection*{Results}

Table~\ref{tab:app-eda-marginals} analyzes the differences in marginal distributions for the forecasts and true values for the horizons of three and seven days.
Note that the difference definition aligns with Section~\ref{subsec:notation}, defined as the difference between the forecasted mean and true value of three and seven days before, as the true value is available when issuing the forecast.
The fraction of positive differences varies between 0.39 and 0.63 for the horizon of three days and between 0.37 and 0.63 for the horizon of seven days.
The variability of differences decreases for the larger horizon for most models; only for the ETS model does it increase.
The 10\%-quantile of the differences is between zero and one for all models and horizons.
Thus, we exclude only differences smaller than one from the trending assessment.
The resulting fraction of included values in the computation is also listed in Table~\ref{tab:app-eda-marginals} and is at least 79\% of the values.

\begin{table}
    \centering
    \input{plots/ed_arrival/10_marginal_analysis}
    \caption{Marginal analysis of the nowcast and true differences. The column (1) shows the fraction of values greater than zero for horizon $l$, $\sigma_{x^{\Delta, l}}$ the standard deviation, and $q_{0.1} (x^{\Delta, l})$ the 10\% quantile of the differences' absolute values.}
    \label{tab:app-eda-marginals}
\end{table}

Table~\ref{tab:app-eda-trending-ratios} lists the trending ratios for all models for three and seven-day horizons.
The trending ratios range from 0.68 to 0.84 for a horizon of three days and from 0.68 to 0.82 for seven days.
The negative and positive trending ratios differ for all models and horizons.
For some models, for example, the GBM-2 model, the positive trending ratio is higher; for some models, for example, the tbats model, the negative trending ratio is higher.
The confidence interval width is at most 0.02 for the trending ratios and at most 0.03 for the positive and negative trending ratios.
The models GBM-2, qreg-1, and Benchmark-1 have the highest positive trending ratio for three and seven days horizon, while Poisson-2 and NBI-2 have the highest negative trending ratio.

Figure~\ref{fig:app-eda-cond-prob} shows the conditional trending plots for the models Benchmark-1, GBM-2, NBI-2, Poisson-2, and qreg-1 for the horizons three and seven days and thus inspects the local trending ability of the models with highest positive and negative trending ratio.
The conditional trending plots show similar courses for the two horizons, while the curves are shifted downwards for the horizon of seven days.
The model's relative trending ability evolves consistently for the two horizons, with the NBI-2 and Poisson-2 models being indistinguishable.
The GBM-2 model outperforms the qreg-1 model for all $x$.
The models NBI-2 and Poisson-2 have the highest trending ability for all negative values of $x$ and the lowest trending ability for all positive values of $x$.
Benchmark-1 lies between the other models for all $x$.

Figure~\ref{fig:app-eda-prob} visualizes the probabilistic trending evaluation for the same subset of models.
The \acfp{bs} are shown in Figure~\ref{fig:app-eda-prob-brier}, and the reliability diagrams for the horizons three and seven days are shown in Figures~\ref{fig:app-eda-prob-rel-3} and \ref{fig:app-eda-prob-rel-7}.
The \acp{bs} are smallest for NBI-2 and Poisson-2 for both horizons, while the \acp{bs} for the other models are larger and differ more.
The qreg-1 model has the highest \ac{bs} for both horizons.
The reliability diagrams of GBM-2 and NBI-2 are also close and show a too-small fraction of increases for the predicted probability overall.
For the other models, the reliability diagrams show a fraction of increases that are too large for the corresponding predicted probability.

\begin{table}
    \centering
    \input{plots/ed_arrival/50_trending_ratio}
    \caption{Trending ratio $\acc$, positive trending ratio $\accp$, and negative trending ratio $\accm$ for the models with the exclusion of zero-containing points for the horizons 72 hours and seven days.}
    \label{tab:app-eda-trending-ratios}
\end{table}

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics{plots/ed_arrival/50_Cond_Prob_lag_3}
    \caption{Horizon three days}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
    \includegraphics{plots/ed_arrival/50_Cond_Prob_lag_7}
    \caption{Horizon seven days}
    \end{subfigure}
    \caption{Conditional trending plots for the horizons three and seven days and the models with the best positive or negative trending ability. The plots of NBI-2 and Poisson-2 are indistinguishable.}
    \label{fig:app-eda-cond-prob}
\end{figure}

\begin{figure}
    \begin{subfigure}{0.32\textwidth}
    \tiny
    \input{plots/ed_arrival/70_brier_scores}
    \caption{Brier Scores for the different models and horizons.}\label{fig:app-eda-prob-brier}
    \end{subfigure}\hspace{0.01\textwidth}%
    \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics{plots/ed_arrival/60_reliability_diagram_lag_3}
    \caption{Reliability diagram for horizon three days.}\label{fig:app-eda-prob-rel-3}
    \end{subfigure}\hspace{0.01\textwidth}%
    \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics{plots/ed_arrival/60_reliability_diagram_lag_7}
    \caption{Reliability diagram for horizon seven days.}\label{fig:app-eda-prob-rel-7}
    \end{subfigure}
    \caption{Probabilistic trending evaluation for the models Benchmark-1, GBM-2, NBI-2, Poisson-2, and qreg-1 for the horizons three and seven days.}
    \label{fig:app-eda-prob}
\end{figure}

\subsubsection*{Discussion}

The trending ability is consistent for the two horizons, with the models' relative trending ability evolving similarly for the two horizons.
The models' trending ability is generally higher for the smaller horizon, but the differences are minor, and confidence intervals overlap.

The trending differs for all models for positive and negative predicted change directions.
While some models, such as GBM-2 and qreg-1, have the highest positive trending ratio, others, such as Poisson-2 and NBI-2, have the highest negative trending ratio.
Thus, the uncertainty of the model's predicted change has to be assessed differently based on the direction.

The results of the probabilistic trending evaluation endorse the point trending assessment and assign the best scores to NBI-2 and Poisson-2. 
The reliability diagrams show that they underestimate the fraction of increases slightly. 

The example shows that trending assessment is detached from standard point evaluation measures.
While the models with the lowest RMSE, NBI-2 and Poisson-2, also have a high trending ability, three models with below-average point evaluation measures, Benchmark-1, GBM-2, and qreg-1, have a high positive trending ability.


\subsection{Invasive and non-invasive blood pressure monitoring} \label{sec:application_measurement}

In the last briefer example, we consider the trending assessment of measurement data.
The data is from the MIMIC-III database, including various information on patients in critical care units of the Beth Israel Deaconess Medical Center in Boston (Massachusetts, USA, \cite{Johnson2016}).
The data is publicly available and also includes numerical measurement data such as heart rate, blood pressure, and oxygen saturation in a waveform database \citetext{\citealp{Moody2017}; available through \citealp{Goldberger2000}}.

For some patients, the data includes \ac{abp} and \ac{nbp} measurements.
While non-invasive blood pressure measurement methods are relatively gentle, they are less accurate than invasive methods.
For an overview of blood pressure measurement methods, see \citet{Saugel2014}.
For critical patients, changes in blood pressure can be crucial for the treatment.
Thus, trending assessment can be performed in addition to standard accuracy analysis~\citep[see, for example, ][]{Mostafa2020}.
Thus, we assess the trending ability of the non-invasive blood pressure measurements compared to the invasive blood pressure measurements.
The database contains 64,168 numerical data records.
One data record includes all numerical measurements for one patient.
The measured signals vary in length, frequency, and type of measurement.
Thus, only a subset of the data contains measurements of \ac{abp} and \ac{nbp} simultaneously.
2,548 include at least one measurement of systolic \ac{abp} and \ac{nbp} and 1,327 include at least one measurement of systolic \ac{abp} and \ac{nbp} at the same time; for the mean \ac{abp} and \ac{nbp}, the numbers are 2,605 and 1,516, respectively.

We consider the horizons of one minute, five minutes, and 15 minutes for the trending assessment, as those are typical intervals of NBP measurements.

\subsubsection*{Results}

Again, we exclude the smallest 10\% of absolute differences in trending assessment.
The resulting four-quadrant plots of the mean and systolic blood pressure measurements for the different horizons are shown in Figure~\ref{fig:app-mimic-4q}.
The number of points in the four-quadrant plot is smaller due to the restriction to data records with measurements of mean or systolic \ac{abp} and \ac{nbp} simultaneously for two consecutive times with the specified horizons.
Thus, we use the \ac{nbp} measurements as test method and the \ac{abp} measurements as gold standard.
For the systolic measurements, 290, 332, and 442 points are available for the horizons of one, five, and 15 minutes; for the mean measurements, 406, 430, and 542.

The trending ratios, including confidence intervals for the different horizons, are listed in Table~\ref{tab:app-mimic-trending-ratios}.
For the measurements with a horizon of one minute, the confidence intervals have lower bounds of 0.5 or slightly above.
For larger horizons, the trending ratio increases.
The difference between positive and negative trending ratios is small for all types and horizons, with overlapping confidence intervals.

Figure~\ref{fig:app-mimic-cond-prob} shows the conditional trending plots for the different horizons and the systolic and mean blood pressure measurements.
It becomes apparent that the systolic measurements have a higher trending ability than the mean measurement, except for small negative predicted changes.
This aligns with the trending ratios, but the confidence intervals overlap.

\begin{figure}
    \centering
    \includegraphics{plots/mimic/plot_4q}
    \caption{Four-quadrant plots for the different horizons and the systolic and mean blood pressure measurements. The upper row contains systolic measurements, and the lower row contains mean measurements. The columns contain the horizons one, five, and 15 minutes.}
    \label{fig:app-mimic-4q}
\end{figure}

\begin{table}
    \centering
    \input{plots/mimic/trending_ratio}
    \caption{Trending ratios for the different horizons and the systolic and mean blood pressure measurements.}
    \label{tab:app-mimic-trending-ratios}
\end{table}

\begin{figure}
    \centering
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics{plots/mimic/cond_prob_diff_nbp_abp_lag1}
        \caption{Horizon one minute.}
    \end{subfigure}\hspace{0.01\textwidth}
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics{plots/mimic/cond_prob_diff_nbp_abp_lag5}
        \caption{Horizon five minutes.}
    \end{subfigure}\hspace{0.01\textwidth}
    \begin{subfigure}[t]{.32\textwidth}
        \includegraphics{plots/mimic/cond_prob_diff_nbp_abp_lag15}
        \caption{Horizon 15 minutes.}
    \end{subfigure}\hspace{0.01\textwidth}
    \caption{Conditional trending plot for the systolic and mean blood pressure measurements and the horizons one, five, and 15 minutes. }
    \label{fig:app-mimic-cond-prob}
\end{figure}




\subsubsection*{Discussion}

The four-quadrant plots contain a considerable number of extreme points.
Whether these points are due to measurement errors or extreme values is not distinguishable.
Some authors argue to exclude the measurements below the 10\%-quantile of the absolute differences and the points above the 90\%-quantile \citep[see][]{Critchley2010}.
We do not follow this approach here, as the extreme values are not necessarily measurement errors and could be particularly relevant.

The differences between positive and negative predicted changes are small in this example.
The positive and negative trending ratios have overlapping confidence intervals, and the conditional trending plots do not contain prominent deviations in the course.
This aligns with the four-quadrant plots, where no apparent asymmetry is visible.

The bootstrap confidence intervals are wide.
The width is around 0.1 for the trending ratio, while it gets up to 0.16 for the negative trending ratio for systolic measurement and the horizon of one minute.
Thus, more measurements would be of interest for a further trending assessment. 

